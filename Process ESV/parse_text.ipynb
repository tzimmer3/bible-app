{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions\n",
    "\n",
    "def parse_bible_text(pageContent):\n",
    "    \"\"\"\n",
    "    Parse bible pageContent and split it into separate entries based on verse numbers.\n",
    "    \n",
    "    This function looks for patterns like:\n",
    "    - 4:1 (chapter:verse at beginning)\n",
    "    - 2( or 3h or 4A etc. (verse number followed by letter)\n",
    "    \n",
    "    Args:\n",
    "        pageContent (str): The raw bible pageContent to parse\n",
    "        \n",
    "    Returns:\n",
    "        list: List of dictionaries containing parsed verses\n",
    "    \"\"\"\n",
    "    \n",
    "    # Remove extra whitespace and normalize pageContent\n",
    "    pageContent = re.sub(r'\\s+', ' ', pageContent.strip())\n",
    "    \n",
    "    # Find all verse markers - looking for number followed by letter or punctuation\n",
    "    # Pattern explanation:\n",
    "    # \\b(\\d+) - word boundary followed by one or more digits (verse number)\n",
    "    # (?=[a-zA-Z(]) - positive lookahead for letter or opening parenthesis\n",
    "    verse_pattern = r'\\b(\\d+)(?=[a-zA-Z(])'\n",
    "    \n",
    "    # Also look for chapter:verse pattern at the beginning\n",
    "    chapter_verse_pattern = r'\\b(\\d+:\\d+)\\s'\n",
    "    \n",
    "    # Find all matches\n",
    "    verse_matches = list(re.finditer(verse_pattern, pageContent))\n",
    "    chapter_matches = list(re.finditer(chapter_verse_pattern, pageContent))\n",
    "    \n",
    "    # Combine and sort all matches by position\n",
    "    all_matches = []\n",
    "    \n",
    "    # Add chapter:verse matches\n",
    "    for match in chapter_matches:\n",
    "        all_matches.append({\n",
    "            'start': match.start(),\n",
    "            'end': match.end(),\n",
    "            'verse_ref': match.group(1),\n",
    "            'type': 'chapter_verse'\n",
    "        })\n",
    "    \n",
    "    # Add verse-only matches\n",
    "    for match in verse_matches:\n",
    "        all_matches.append({\n",
    "            'start': match.start(),\n",
    "            'end': match.start() + len(match.group(1)),  # Only include the number, preserve letter\n",
    "            'verse_ref': match.group(1),\n",
    "            'type': 'verse'\n",
    "        })\n",
    "    \n",
    "    # Sort by position\n",
    "    all_matches.sort(key=lambda x: x['start'])\n",
    "    \n",
    "    # Split text based on matches\n",
    "    parsed_verses = []\n",
    "    \n",
    "    if not all_matches:\n",
    "        # No verses found, return the whole pageContent\n",
    "        return [{'verse_ref': 'unknown', 'pageContent': pageContent.strip(), 'type': 'unknown'}]\n",
    "    \n",
    "    # Handle pageContent before first verse (usually heading)\n",
    "    if all_matches[0]['start'] > 0:\n",
    "        heading_pageContent = pageContent[:all_matches[0]['start']].strip()\n",
    "        if heading_pageContent:\n",
    "            parsed_verses.append({\n",
    "                'verse_ref': 'heading',\n",
    "                'pageContent': heading_pageContent,\n",
    "                'type': 'heading'\n",
    "            })\n",
    "    \n",
    "    # Process each verse\n",
    "    for i, match in enumerate(all_matches):\n",
    "        # Determine where this verse ends\n",
    "        if i + 1 < len(all_matches):\n",
    "            verse_end = all_matches[i + 1]['start']\n",
    "        else:\n",
    "            verse_end = len(pageContent)\n",
    "        \n",
    "        # Extract verse pageContent\n",
    "        verse_text = pageContent[match['end']:verse_end].strip()\n",
    "        \n",
    "        if verse_text:  # Only add if there's actual content\n",
    "            parsed_verses.append({\n",
    "                'verse_ref': match['verse_ref'],\n",
    "                'pageContent': verse_text,\n",
    "                'type': match['type']\n",
    "            })\n",
    "    \n",
    "    return parsed_verses\n",
    "\n",
    "\n",
    "def clean_csv_data(df, text_column='pageContent'):\n",
    "    \"\"\"\n",
    "    Apply the parsing function to a pandas DataFrame.\n",
    "    \n",
    "    Args:\n",
    "        df (DataFrame): The input DataFrame\n",
    "        text_column (str): Name of the column containing the text to parse\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame: New DataFrame with parsed verses\n",
    "    \"\"\"\n",
    "    \n",
    "    all_parsed = []\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        text = str(row[text_column])\n",
    "        parsed_verses = parse_bible_text(text)\n",
    "        \n",
    "        for verse in parsed_verses:\n",
    "            new_row = row.copy()\n",
    "            new_row['original_index'] = index\n",
    "            new_row['verse_ref'] = verse['verse_ref']\n",
    "            new_row['parsed_text'] = verse['pageContent']\n",
    "            new_row['verse_type'] = verse['type']\n",
    "            all_parsed.append(new_row)\n",
    "    \n",
    "    return pd.DataFrame(all_parsed)\n",
    "\n",
    "\n",
    "# Replace special characters like â€œ with proper quotes\n",
    "def clean_special_characters(text):\n",
    "    \"\"\"Clean common encoding issues in text\"\"\"\n",
    "    replacements = {\n",
    "        'â€œ': '\"',\n",
    "        'â€': '\"', \n",
    "        'â€™': \"'\",\n",
    "        'â€˜': \"'\",\n",
    "        'â€\"': '—',\n",
    "        'â€\"': '–'\n",
    "    }\n",
    "    \n",
    "    # Apply all replacements - this handles characters anywhere in the text\n",
    "    for old, new in replacements.items():\n",
    "        text = text.replace(old, new)\n",
    "    \n",
    "    return text\n",
    "\n",
    "\n",
    "def consolidate_rows_without_verses(df, text_column='pageContent'):\n",
    "    \"\"\"\n",
    "    Consolidate rows by appending text from rows without verse numbers \n",
    "    to the previous row.\n",
    "    \n",
    "    Args:\n",
    "        df (DataFrame): The input DataFrame\n",
    "        text_column (str): Name of the column containing the text to check\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame: New DataFrame with consolidated rows\n",
    "    \"\"\"\n",
    "    \n",
    "    def has_verse_numbers(text):\n",
    "        \"\"\"Check if text contains verse number patterns\"\"\"\n",
    "        if pd.isna(text) or text.strip() == '':\n",
    "            return False\n",
    "            \n",
    "        text = str(text)\n",
    "        \n",
    "        # Check for chapter:verse pattern (e.g., \"4:1\")\n",
    "        chapter_verse_pattern = r'\\b\\d+:\\d+\\b'\n",
    "        if re.search(chapter_verse_pattern, text):\n",
    "            return True\n",
    "            \n",
    "        # Check for verse number followed by letter or punctuation (e.g., \"2But\", \"3(\")\n",
    "        verse_pattern = r'\\b\\d+(?=[a-zA-Z(])'\n",
    "        if re.search(verse_pattern, text):\n",
    "            return True\n",
    "            \n",
    "        return False\n",
    "    \n",
    "    # Create a copy of the dataframe to work with\n",
    "    consolidated_df = df.copy()\n",
    "    consolidated_rows = []\n",
    "    \n",
    "    i = 0\n",
    "    while i < len(consolidated_df):\n",
    "        current_row = consolidated_df.iloc[i].copy()\n",
    "        current_text = str(current_row[text_column])\n",
    "        \n",
    "        # Check if current row has verse numbers\n",
    "        if has_verse_numbers(current_text):\n",
    "            # This row has verse numbers, keep it as is\n",
    "            consolidated_rows.append(current_row)\n",
    "        else:\n",
    "            # This row doesn't have verse numbers\n",
    "            if len(consolidated_rows) > 0:\n",
    "                # Append to the previous row\n",
    "                previous_row = consolidated_rows[-1]\n",
    "                previous_text = str(previous_row[text_column])\n",
    "                \n",
    "                # Combine the text with a space\n",
    "                combined_text = previous_text + \" \" + current_text\n",
    "                previous_row[text_column] = combined_text\n",
    "                \n",
    "                print(f\"Consolidated row {i}: '{current_text[:50]}...' -> appended to previous row\")\n",
    "            else:\n",
    "                # No previous row to append to, keep this row\n",
    "                consolidated_rows.append(current_row)\n",
    "                print(f\"Row {i}: No previous row to append to, keeping as standalone\")\n",
    "        \n",
    "        i += 1\n",
    "    \n",
    "    # Convert back to DataFrame\n",
    "    result_df = pd.DataFrame(consolidated_rows)\n",
    "    result_df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    print(f\"\\nConsolidation complete:\")\n",
    "    print(f\"  Original rows: {len(df)}\")\n",
    "    print(f\"  Consolidated rows: {len(result_df)}\")\n",
    "    print(f\"  Rows merged: {len(df) - len(result_df)}\")\n",
    "    \n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables\n",
    "\n",
    "# Import data\n",
    "import_filename = 'ESV_extracted_text.csv'\n",
    "import_filepath = \"C:\\\\Users\\\\hlmq\\\\code\\\\bible-app\\\\Process ESV\\\\Out\\\\\"\n",
    "# Export data\n",
    "export_filename = 'ESV_Bible_Extracted_and_Parsed.csv'\n",
    "export_filepath = \"C:\\\\Users\\\\hlmq\\\\code\\\\bible-app\\\\Process ESV\\\\Out\\\\\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>docName</th>\n",
       "      <th>pageContent</th>\n",
       "      <th>pageNumber</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ESV Bible.pdf</td>\n",
       "      <td>The Word Became Flesh\\r\\n1:1 In the beginning ...</td>\n",
       "      <td>4998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ESV Bible.pdf</td>\n",
       "      <td>right to become children of God, 13who were bo...</td>\n",
       "      <td>4999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ESV Bible.pdf</td>\n",
       "      <td>The Testimony of John the Baptist\\r\\n19And thi...</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ESV Bible.pdf</td>\n",
       "      <td>baptizing.</td>\n",
       "      <td>5001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ESV Bible.pdf</td>\n",
       "      <td>Behold, the Lamb of God\\r\\n29The next day he s...</td>\n",
       "      <td>5002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         docName                                        pageContent  \\\n",
       "0  ESV Bible.pdf  The Word Became Flesh\\r\\n1:1 In the beginning ...   \n",
       "1  ESV Bible.pdf  right to become children of God, 13who were bo...   \n",
       "2  ESV Bible.pdf  The Testimony of John the Baptist\\r\\n19And thi...   \n",
       "3  ESV Bible.pdf                                         baptizing.   \n",
       "4  ESV Bible.pdf  Behold, the Lamb of God\\r\\n29The next day he s...   \n",
       "\n",
       "   pageNumber  \n",
       "0        4998  \n",
       "1        4999  \n",
       "2        5000  \n",
       "3        5001  \n",
       "4        5002  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import Data\n",
    "df = pd.read_csv(str(import_filepath)+str(import_filename))\n",
    "\n",
    "# Delete rows with null values in 'pageContent' column\n",
    "mask = df['pageContent'].isnull()\n",
    "df = df[~mask]\n",
    "\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Character cleaning applied.\n",
      "Consolidated row 3: 'baptizing....' -> appended to previous row\n",
      "Consolidated row 7: 'of God ascending and descending on the Son of\n",
      "Man...' -> appended to previous row\n",
      "Consolidated row 11: 'from the dead, his disciples remembered that he\n",
      "h...' -> appended to previous row\n",
      "Consolidated row 78: 'So the Pharisees said to one another, “You see\n",
      "th...' -> appended to previous row\n",
      "Consolidated row 81: 'the light, believe in the light, that you may beco...' -> appended to previous row\n",
      "Consolidated row 89: 'was night....' -> appended to previous row\n",
      "Consolidated row 105: 'these things to you, that in me you may have peace...' -> appended to previous row\n",
      "Consolidated row 128: 'announced to the disciples, “I have seen the Lord”...' -> appended to previous row\n",
      "\n",
      "Consolidation complete:\n",
      "  Original rows: 135\n",
      "  Consolidated rows: 127\n",
      "  Rows merged: 8\n",
      "\n",
      "Parsing complete. Expanded from 135 to 982 rows\n",
      "\n",
      "Parsing complete. Expanded from 135 to 982 rows\n"
     ]
    }
   ],
   "source": [
    "# Apply character cleaning first\n",
    "if 'pageContent' in df.columns:\n",
    "    df['pageContent'] = df['pageContent'].apply(clean_special_characters)\n",
    "    print(\"\\nCharacter cleaning applied.\")\n",
    "\n",
    "# Apply the parsing function\n",
    "consolidated_df = consolidate_rows_without_verses(df, text_column='pageContent')\n",
    "cleaned_df = clean_csv_data(df, text_column='pageContent')\n",
    "print(f\"\\nParsing complete. Expanded from {len(df)} to {len(cleaned_df)} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== EXPORT ===\n",
      "Cleaned data saved to: C:\\Users\\hlmq\\code\\bible-app\\Process ESV\\Out\\ESV_Bible_Extracted_and_Parsed.csv\n"
     ]
    }
   ],
   "source": [
    "output_file = str(export_filepath) + str(export_filename)\n",
    "cleaned_df.to_csv(output_file, index=False)\n",
    "print(f\"\\n=== EXPORT ===\")\n",
    "print(f\"Cleaned data saved to: {output_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "espReports_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
