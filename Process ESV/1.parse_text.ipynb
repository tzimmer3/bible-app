{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions\n",
    "\n",
    "def parse_bible_text(pageContent):\n",
    "    \"\"\"\n",
    "    Parse bible pageContent and split it into separate entries based on verse numbers.\n",
    "    \n",
    "    This function looks for patterns like:\n",
    "    - 4:1 (chapter:verse at beginning)\n",
    "    - 2( or 3h or 4A etc. (verse number followed by letter)\n",
    "    \n",
    "    Args:\n",
    "        pageContent (str): The raw bible pageContent to parse\n",
    "        \n",
    "    Returns:\n",
    "        list: List of dictionaries containing parsed verses\n",
    "    \"\"\"\n",
    "    \n",
    "    # Remove extra whitespace and normalize pageContent\n",
    "    pageContent = re.sub(r'\\s+', ' ', pageContent.strip())\n",
    "    \n",
    "    # Find all verse markers - looking for number followed by letter or punctuation\n",
    "    # Pattern explanation:\n",
    "    # \\b(\\d+) - word boundary followed by one or more digits (verse number)\n",
    "    # (?=[a-zA-Z(]) - positive lookahead for letter or opening parenthesis\n",
    "    verse_pattern = r'\\b(\\d+)(?=[a-zA-Z(])'\n",
    "    \n",
    "    # Also look for chapter:verse pattern at the beginning\n",
    "    chapter_verse_pattern = r'\\b(\\d+:\\d+)\\s'\n",
    "    \n",
    "    # Find all matches\n",
    "    verse_matches = list(re.finditer(verse_pattern, pageContent))\n",
    "    chapter_matches = list(re.finditer(chapter_verse_pattern, pageContent))\n",
    "    \n",
    "    # Combine and sort all matches by position\n",
    "    all_matches = []\n",
    "    \n",
    "    # Add chapter:verse matches\n",
    "    for match in chapter_matches:\n",
    "        all_matches.append({\n",
    "            'start': match.start(),\n",
    "            'end': match.end(),\n",
    "            'verse_ref': match.group(1),\n",
    "            'type': 'chapter_verse'\n",
    "        })\n",
    "    \n",
    "    # Add verse-only matches\n",
    "    for match in verse_matches:\n",
    "        all_matches.append({\n",
    "            'start': match.start(),\n",
    "            'end': match.start() + len(match.group(1)),  # Only include the number, preserve letter\n",
    "            'verse_ref': match.group(1),\n",
    "            'type': 'verse'\n",
    "        })\n",
    "    \n",
    "    # Sort by position\n",
    "    all_matches.sort(key=lambda x: x['start'])\n",
    "    \n",
    "    # Split text based on matches\n",
    "    parsed_verses = []\n",
    "    \n",
    "    if not all_matches:\n",
    "        # No verses found, return the whole pageContent\n",
    "        return [{'verse_ref': 'unknown', 'pageContent': pageContent.strip(), 'type': 'unknown'}]\n",
    "    \n",
    "    # Handle pageContent before first verse (usually heading)\n",
    "    if all_matches[0]['start'] > 0:\n",
    "        heading_pageContent = pageContent[:all_matches[0]['start']].strip()\n",
    "        if heading_pageContent:\n",
    "            parsed_verses.append({\n",
    "                'verse_ref': 'heading',\n",
    "                'pageContent': heading_pageContent,\n",
    "                'type': 'heading'\n",
    "            })\n",
    "    \n",
    "    # Process each verse\n",
    "    for i, match in enumerate(all_matches):\n",
    "        # Determine where this verse ends\n",
    "        if i + 1 < len(all_matches):\n",
    "            verse_end = all_matches[i + 1]['start']\n",
    "        else:\n",
    "            verse_end = len(pageContent)\n",
    "        \n",
    "        # Extract verse pageContent\n",
    "        verse_text = pageContent[match['end']:verse_end].strip()\n",
    "        \n",
    "        if verse_text:  # Only add if there's actual content\n",
    "            parsed_verses.append({\n",
    "                'verse_ref': match['verse_ref'],\n",
    "                'pageContent': verse_text,\n",
    "                'type': match['type']\n",
    "            })\n",
    "    \n",
    "    return parsed_verses\n",
    "\n",
    "\n",
    "def clean_csv_data(df, text_column='pageContent'):\n",
    "    \"\"\"\n",
    "    Apply the parsing function to a pandas DataFrame.\n",
    "    \n",
    "    Args:\n",
    "        df (DataFrame): The input DataFrame\n",
    "        text_column (str): Name of the column containing the text to parse\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame: New DataFrame with parsed verses\n",
    "    \"\"\"\n",
    "    \n",
    "    all_parsed = []\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        text = str(row[text_column])\n",
    "        parsed_verses = parse_bible_text(text)\n",
    "        \n",
    "        for verse in parsed_verses:\n",
    "            new_row = row.copy()\n",
    "            new_row['original_index'] = index\n",
    "            new_row['verse_ref'] = verse['verse_ref']\n",
    "            new_row['parsed_text'] = verse['pageContent']\n",
    "            new_row['verse_type'] = verse['type']\n",
    "            all_parsed.append(new_row)\n",
    "    \n",
    "    return pd.DataFrame(all_parsed)\n",
    "\n",
    "\n",
    "# # Replace special characters like â€œ with proper quotes\n",
    "# def clean_special_characters(text):\n",
    "#     \"\"\"\n",
    "#     Enhanced function to clean common encoding issues in text.\n",
    "#     This version handles more Unicode variations and uses regex for better matching.\n",
    "#     \"\"\"\n",
    "#     if pd.isna(text) or text == '':\n",
    "#         return text\n",
    "    \n",
    "#     text = str(text)\n",
    "    \n",
    "#     # Define replacements with more comprehensive patterns\n",
    "#     replacements = [\n",
    "#         # Various quote patterns\n",
    "#         (r'â€œ', '\"'),  # Left double quote\n",
    "#         (r'â€', '\"'),   # Right double quote  \n",
    "#         (r'â€™', \"'\"),  # Right single quote\n",
    "#         (r'â€˜', \"'\"),  # Left single quote\n",
    "#         (r'â€\"', '—'),  # Em dash\n",
    "#         (r'â€\"', '–'),  # En dash\n",
    "#         (r'â€¦', '...'), # Ellipsis\n",
    "        \n",
    "#         # Additional common encoding issues\n",
    "#         (r'Â ', ' '),    # Non-breaking space issues\n",
    "#         (r'Â', ''),      # Standalone Â characters\n",
    "        \n",
    "#         # Handle any remaining â followed by euro and other chars (fallback)\n",
    "#         (r'â€[œ\"]', '\"'),  # Various quote combinations\n",
    "#         (r'â€[™˜]', \"'\"),  # Various apostrophe combinations\n",
    "#         (r'â€[—–]', '—'),  # Various dash combinations\n",
    "#     ]\n",
    "    \n",
    "#     # Apply all replacements\n",
    "#     for pattern, replacement in replacements:\n",
    "#         text = re.sub(pattern, replacement, text)\n",
    "    \n",
    "#     return text\n",
    "\n",
    "\n",
    "def clean_special_characters(text):\n",
    "    \"\"\"\n",
    "    Cleans special characters from the text.\n",
    "    \"\"\"\n",
    "    if pd.isna(text) or text == '':\n",
    "        return text\n",
    "    \n",
    "    # Define a regex pattern to match common special characters\n",
    "    pattern = r'[^\\w\\s,.!?;:\\'\\\"-]'\n",
    "    \n",
    "    # Replace special characters with an empty string\n",
    "    cleaned_text = re.sub(pattern, '', text)\n",
    "    \n",
    "    return cleaned_text\n",
    "\n",
    "\n",
    "def has_verse_numbers(text):\n",
    "    \"\"\"Check if text contains verse number patterns\"\"\"\n",
    "    if pd.isna(text) or text.strip() == '':\n",
    "        return False\n",
    "        \n",
    "    text = str(text)\n",
    "    \n",
    "    # Check for chapter:verse pattern (e.g., \"4:1\")\n",
    "    chapter_verse_pattern = r'\\b\\d+:\\d+\\b'\n",
    "    if re.search(chapter_verse_pattern, text):\n",
    "        return True\n",
    "        \n",
    "    # Check for verse number followed by letter or punctuation (e.g., \"2But\", \"3(\")\n",
    "    verse_pattern = r'\\b\\d+(?=[a-zA-Z(])'\n",
    "    if re.search(verse_pattern, text):\n",
    "        return True\n",
    "        \n",
    "    return False\n",
    "\n",
    "\n",
    "def consolidate_rows_without_verses(df, text_column='pageContent'):\n",
    "    \"\"\"\n",
    "    Consolidate rows by appending text from rows without verse numbers \n",
    "    to the previous row.\n",
    "    \n",
    "    Args:\n",
    "        df (DataFrame): The input DataFrame\n",
    "        text_column (str): Name of the column containing the text to check\n",
    "        verse_column (str): Name of the column containing verse references\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame: New DataFrame with consolidated rows\n",
    "    \"\"\"\n",
    "    \n",
    "    def has_verse_numbers(text):\n",
    "        \"\"\"Check if text contains verse number patterns\"\"\"\n",
    "        if pd.isna(text) or text.strip() == '':\n",
    "            return False\n",
    "            \n",
    "        text = str(text)\n",
    "        \n",
    "        # Check for chapter:verse pattern (e.g., \"4:1\")\n",
    "        chapter_verse_pattern = r'\\b\\d+:\\d+\\b'\n",
    "        if re.search(chapter_verse_pattern, text):\n",
    "            return True\n",
    "            \n",
    "        # Check for verse number followed by letter or punctuation (e.g., \"2But\", \"3(\")\n",
    "        verse_pattern = r'\\b\\d+(?=[a-zA-Z(])'\n",
    "        if re.search(verse_pattern, text):\n",
    "            return True\n",
    "            \n",
    "        return False\n",
    "    \n",
    "    # Create a copy of the dataframe to work with\n",
    "    consolidated_df = df.copy()\n",
    "    consolidated_rows = []\n",
    "    \n",
    "    i = 0\n",
    "    while i < len(consolidated_df):\n",
    "        current_row = consolidated_df.iloc[i].copy()\n",
    "        current_text = str(current_row[text_column])\n",
    "        \n",
    "        # Check if current row has verse numbers\n",
    "        if has_verse_numbers(current_text):\n",
    "            # This row has verse numbers, keep it as is\n",
    "            consolidated_rows.append(current_row)\n",
    "        else:\n",
    "            # This row doesn't have verse numbers\n",
    "            if len(consolidated_rows) > 0:\n",
    "                # Append to the previous row\n",
    "                previous_row = consolidated_rows[-1]\n",
    "                previous_text = str(previous_row[text_column])\n",
    "                \n",
    "                # Combine the text with a space\n",
    "                combined_text = previous_text + \" \" + current_text\n",
    "                previous_row[text_column] = combined_text\n",
    "                \n",
    "                print(f\"Consolidated row {i}: '{current_text[:50]}...' -> appended to previous row\")\n",
    "            else:\n",
    "                # No previous row to append to, keep this row\n",
    "                consolidated_rows.append(current_row)\n",
    "                print(f\"Row {i}: No previous row to append to, keeping as standalone\")\n",
    "        \n",
    "        i += 1\n",
    "    \n",
    "    # Convert back to DataFrame\n",
    "    result_df = pd.DataFrame(consolidated_rows)\n",
    "    result_df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    return result_df\n",
    "\n",
    "\n",
    "# Append pageContent values to the previous row when they have a verse_ref that is 'heading' or 'unknown'\n",
    "def consolidate_rows_mid_section(df, text_column='pageContent'):\n",
    "    \"\"\"\n",
    "    Consolidate rows by appending text from rows without verse numbers \n",
    "    to the previous row.\n",
    "    \n",
    "    Args:\n",
    "        df (DataFrame): The input DataFrame\n",
    "        text_column (str): Name of the column containing the text to check\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame: New DataFrame with consolidated rows\n",
    "    \"\"\"\n",
    "    \n",
    "    consolidated_df = df.copy()\n",
    "    consolidated_rows = []\n",
    "    \n",
    "    i = 0\n",
    "    while i < len(consolidated_df):\n",
    "        current_row = consolidated_df.iloc[i].copy()\n",
    "        current_text = str(current_row[text_column])\n",
    "        \n",
    "        # Check if current row has a verse_ref that is 'heading' or 'unknown'\n",
    "        if current_row.get('verse_ref') in ['heading', 'unknown']:\n",
    "            # This row is a heading or unknown, append to previous row\n",
    "            if len(consolidated_rows) > 0:\n",
    "                previous_row = consolidated_rows[-1]\n",
    "                previous_text = str(previous_row[text_column])\n",
    "                \n",
    "                # Combine the text with a space\n",
    "                combined_text = previous_text + \" \" + current_text\n",
    "                previous_row[text_column] = combined_text\n",
    "                \n",
    "                print(f\"Consolidated row {i}: '{current_text[:50]}...' -> appended to previous row\")\n",
    "            else:\n",
    "                # No previous row to append to, keep this row\n",
    "                consolidated_rows.append(current_row)\n",
    "                print(f\"Row {i}: No previous row to append to, keeping as standalone\")\n",
    "        else:\n",
    "            # This row has a valid verse_ref, keep it as is\n",
    "            consolidated_rows.append(current_row)\n",
    "        \n",
    "        i += 1\n",
    "    \n",
    "    # Convert back to DataFrame\n",
    "    result_df = pd.DataFrame(consolidated_rows)\n",
    "    result_df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    return result_df\n",
    "\n",
    "\n",
    "def combine_rows_by_condition(data):\n",
    "    \"\"\"\n",
    "    Combines rows in a table when the first word starts with a lowercase letter or number.\n",
    "    \n",
    "    Parameters:\n",
    "    data: Can be a list of strings, pandas DataFrame, or list of lists\n",
    "    \n",
    "    Returns:\n",
    "    Combined data in the same format as input\n",
    "    \"\"\"\n",
    "    \n",
    "    # Convert input to list of strings for processing\n",
    "    if isinstance(data, pd.DataFrame):\n",
    "        # If DataFrame, convert to list of strings (assuming single column or join columns)\n",
    "        if data.shape[1] == 1:\n",
    "            string_list = data.iloc[:, 0].tolist()\n",
    "        else:\n",
    "            # Join multiple columns with space\n",
    "            string_list = data.apply(lambda row: ' '.join(row.astype(str)), axis=1).tolist()\n",
    "        is_dataframe = True\n",
    "    elif isinstance(data, list) and len(data) > 0 and isinstance(data[0], list):\n",
    "        # List of lists - join each sublist\n",
    "        string_list = [' '.join(map(str, row)) for row in data]\n",
    "        is_dataframe = False\n",
    "        is_list_of_lists = True\n",
    "    else:\n",
    "        # Assume list of strings\n",
    "        string_list = data.copy()\n",
    "        is_dataframe = False\n",
    "        is_list_of_lists = False\n",
    "    \n",
    "    if not string_list:\n",
    "        return data\n",
    "    \n",
    "    combined_list = []\n",
    "    \n",
    "    for i, current_row in enumerate(string_list):\n",
    "        current_row = str(current_row).strip()\n",
    "        \n",
    "        if not current_row:\n",
    "            combined_list.append(current_row)\n",
    "            continue\n",
    "            \n",
    "        # Get the first word\n",
    "        words = current_row.split()\n",
    "        if not words:\n",
    "            combined_list.append(current_row)\n",
    "            continue\n",
    "            \n",
    "        first_word = words[0]\n",
    "        \n",
    "        # Check if first character is lowercase or digit\n",
    "        first_char = first_word[0]\n",
    "        should_combine = first_char.islower() or first_char.isdigit()\n",
    "        \n",
    "        if should_combine and combined_list:\n",
    "            # Append to previous row with a space\n",
    "            combined_list[-1] = combined_list[-1] + \" \" + current_row\n",
    "        else:\n",
    "            # Add as new row\n",
    "            combined_list.append(current_row)\n",
    "    \n",
    "    # Convert back to original format\n",
    "    if isinstance(data, pd.DataFrame):\n",
    "        if data.shape[1] == 1:\n",
    "            return pd.DataFrame(combined_list, columns=data.columns)\n",
    "        else:\n",
    "            # For multi-column DataFrames, return as single column\n",
    "            return pd.DataFrame(combined_list, columns=['combined_text'])\n",
    "    elif is_list_of_lists:\n",
    "        # Convert back to list of lists (single item lists)\n",
    "        return [[item] for item in combined_list]\n",
    "    else:\n",
    "        return combined_list\n",
    "    \n",
    "\n",
    "# Remove all instances of '[number]' in a text string.\n",
    "\n",
    "def remove_square_brackets(text):\n",
    "    \"\"\"\n",
    "    Remove all instances of '[number]' in a text string.\n",
    "    \n",
    "    Args:\n",
    "        text (str): The input text\n",
    "        \n",
    "    Returns:\n",
    "        str: Text with all '[number]' patterns removed\n",
    "    \"\"\"\n",
    "    if pd.isna(text):\n",
    "        return text\n",
    "    \n",
    "    # Use regex to remove patterns like [1], [2], etc.\n",
    "    return re.sub(r'\\[\\d+\\]', '', str(text)).strip()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables\n",
    "\n",
    "# Import data\n",
    "import_filename = 'ESV_extracted_text.csv'\n",
    "import_filepath = \"C:\\\\Users\\\\hlmq\\\\code\\\\bible-app\\\\Process ESV\\\\Out\\\\\"\n",
    "# Export data\n",
    "export_filename = 'ESV_Bible_Extracted_and_Parsed.csv'\n",
    "export_filepath = \"C:\\\\Users\\\\hlmq\\\\code\\\\bible-app\\\\Process ESV\\\\Out\\\\\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>docName</th>\n",
       "      <th>pageContent</th>\n",
       "      <th>pageNumber</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ESV Bible.pdf</td>\n",
       "      <td>JOHN\\nChapter 1\\nChapter 2\\nChapter 3\\nChapter...</td>\n",
       "      <td>4996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ESV Bible.pdf</td>\n",
       "      <td>The Word Became Flesh\\n1:1 In the beginning wa...</td>\n",
       "      <td>4998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ESV Bible.pdf</td>\n",
       "      <td>right to become children of God, 13who were bo...</td>\n",
       "      <td>4999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ESV Bible.pdf</td>\n",
       "      <td>The Testimony of John the Baptist\\n19And this ...</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ESV Bible.pdf</td>\n",
       "      <td>baptizing.</td>\n",
       "      <td>5001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         docName                                        pageContent  \\\n",
       "0  ESV Bible.pdf  JOHN\\nChapter 1\\nChapter 2\\nChapter 3\\nChapter...   \n",
       "1  ESV Bible.pdf  The Word Became Flesh\\n1:1 In the beginning wa...   \n",
       "2  ESV Bible.pdf  right to become children of God, 13who were bo...   \n",
       "3  ESV Bible.pdf  The Testimony of John the Baptist\\n19And this ...   \n",
       "4  ESV Bible.pdf                                         baptizing.   \n",
       "\n",
       "   pageNumber  \n",
       "0        4996  \n",
       "1        4998  \n",
       "2        4999  \n",
       "3        5000  \n",
       "4        5001  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import Data\n",
    "df = pd.read_csv(str(import_filepath)+str(import_filename))\n",
    "\n",
    "# Delete rows with null values in 'pageContent' column\n",
    "mask = df['pageContent'].isnull()\n",
    "df = df[~mask]\n",
    "\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Parsing complete. Expanded from 1154 to 1154 rows\n"
     ]
    }
   ],
   "source": [
    "# Apply character cleaning first\n",
    "if 'pageContent' in df.columns:\n",
    "    df['pageContent'] = df['pageContent'].apply(clean_special_characters)\n",
    "    df['pageContent'] = df['pageContent'].apply(remove_square_brackets)\n",
    "    content = combine_rows_by_condition(df['pageContent'].tolist())\n",
    "    df = pd.DataFrame(content, columns=['pageContent'])\n",
    "    df = clean_csv_data(df, text_column='pageContent')\n",
    "\n",
    "print(f\"\\nParsing complete. Expanded from {len(df)} to {len(df)} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== EXPORT ===\n",
      "Cleaned data saved to: C:\\Users\\hlmq\\code\\bible-app\\Process ESV\\Out\\ESV_Bible_Extracted_and_Parsed.csv\n"
     ]
    }
   ],
   "source": [
    "output_file = str(export_filepath) + str(export_filename)\n",
    "df.to_csv(output_file, index=False)\n",
    "print(f\"\\n=== EXPORT ===\")\n",
    "print(f\"Cleaned data saved to: {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "espReports_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
